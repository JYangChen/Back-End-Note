



## 进程与线程的区别

- 进程是一个“执行中的程序”，是系统进行**资源分配和调度**的一个独立单位
- 线程是进程的一个实体，一个进程中一般拥有多个线程。线程之间**共享地址空间**和其它资源（所以通信和同步等操作,线程比进程更加容易）
- 线程一般不拥有系统资源，但是也有一些必不可少的资源（使用ThreadLocal存储）
- 线程上下文的切换比进程上下文切换要快很多。



### **线程上下文切换比进程上下文切换快的原因**

- **进程切换时**，涉及到当前进程的CPU环境的保存和新被调度运行进程的CPU环境的设置
- **线程切换时**，仅需要保存和设置少量的寄存器内容，不涉及存储管理方面的操作

### **线程可以拥有独属于自己的资源吗**？

- 通过ThreadLocal可以存储线程的特有对象

### 进程之间常见的通信方式

- 通过使用套接字Socket来实现不同机器间的进程通信
- 通过映射一段可以被多个进程访问的共享内存来进行通信
- 通过写进程和读进程利用管道进行通信



## 多线程与单线程的关系

- 多线程是指在**一个进程中，并发执行了多个线程**，每个线程都实现了不同的功能
- 在单核CPU中，将CPU分为很小的时间片，在每一时刻只能有一个线程在执行，是一种微观上轮流占用CPU的机制。由于**CPU轮询**的速度非常快，所以看起来像是“同时”在执行一样
- 多线程会存在**线程上下文切换**，会导致程序执行速度变慢
- 多线程不会提高程序的执行速度，反而会降低速度。但是对于用户来说，可以**减少用户的等待响应时间，提高了资源的利用效率**

### 多线程和单线程之间的区别

- **多线程并发利用了CPU轮询时间片的特点**，在一个线程进入阻塞状态时，可以快速切换到其余线程执行其余操作，这有利于**提高资源的利用率，最大限度的利用系统提供的处理能力**，**有效减少了用户的等待响应时间**
- 多线程并发编程也会带来数据的安全问题，线程之间的竞争也会导致线程死锁和锁死等**活性故障**。线程之间的上下文切换也会带来**额外的开销**等问题

## 线程的状态有哪些

线程的状态包括 **新建状态，运行状态，阻塞等待状态和消亡状态。**其中阻塞等待状态又分为**BLOCKED, WAITING和TIMED_WAITING**状态



## 多线程编程中常用的函数比较

### **sleep 和 wait 的区别：**

- **sleep方法：**是Thread类的静态方法，当前线程将睡眠n毫秒，线程进入阻塞状态。当睡眠时间到了，会解除阻塞，进入可运行状态，等待CPU的到来。睡眠不释放锁（如果有的话）。
- **wait方法：**是Object的方法，必须与synchronized关键字一起使用，线程进入阻塞状态，当notify或者notifyall被调用后，会解除阻塞。但是，只有**重新占用互斥锁**之后才会进入可运行状态。睡眠时，会释放互斥锁。

### **join 方法：**

当前线程调用，则其它线程全部停止，等待当前线程执行完毕，接着执行。

### **yield 方法：**

该方法使得线程放弃当前分得的 CPU 时间。但是不使线程阻塞，即线程仍处于可执行状态，随时可能再次分得 CPU 时间。



## 线程活性故障有哪些

由于资源的稀缺性或者程序自身的问题导致线程**一直处于非Runnable状态**，并且其处理的任务**一直无法完成的现象**被称为是线程活性故障。常见的线程活性故障包括**死锁，锁死，活锁与线程饥饿**。

### 线程死锁

死锁是最常见的一种线程活性故障。死锁的起因是多个线程之间相互等待对方而被永远暂停（处于非Runnable）。死锁的产生必须满足如下**四个必要条件：**

- **资源互斥**：一个资源每次只能被一个线程使用
- **请求与保持条件**：一个线程因请求资源而阻塞时，对已获得的资源保持不放
- **不剥夺条件**：线程已经获得的资源，在未使用完之前，不能强行剥夺
- **循环等待条件**：若干线程之间形成一种头尾相接的循环等待资源关系

### 如何避免死锁的发生

- **粗锁法：**使用一个粒度粗的锁来消除“请求与保持条件”，缺点是会明显降低程序的并发性能并且会导致资源的浪费。

- **锁排序法：（必须回答出来的点）**

  **指定获取锁的顺序**，比如某个线程只有获得A锁和B锁，才能对某资源进行操作，在多线程条件下，如何避免死锁？

  通过指定锁的获取顺序，比如规定，只有获得A锁的线程才有资格获取B锁，按顺序获取锁就可以避免死锁。这通常被认为是解决死锁很好的一种方法。

- 使用**显式锁**中的**ReentrantLock.try(long,TimeUnit)**来申请锁

### 线程锁死

**线程锁死是另一种常见的线程活性故障，与线程死锁不可以混为一谈。**

**线程锁死的定义如下：**

- 线程锁死是指等待线程由于唤醒其所需的条件永远无法成立，或者其他线程无法唤醒这个线程而一直处于非运行状态（线程并未终止）导致其任务 一直无法进展。

- 线程死锁和线程锁死的外部表现是一致的，即故障线程一直处于非运行状态使得其所执行的任务没有进展。但是锁死的产生条件和线程死锁不一样，即使产生死锁的4个必要条件都没有发生，线程锁死仍然可能已经发生。

### 线程锁死分类

- **信号丢失锁死：**
  - 信号丢失锁死是因为没有对应的通知线程来将等待线程唤醒，导致等待线程一直处于等待状态。
  - **典型例子**是等待线程在执行Object.wait( )/Condition.await( )前**没有对保护条件进行判断，而此时保护条件实际上可能已经成立**，此后可能并无其他线程更新相应保护条件涉及的共享变量使其成立并通知等待线程，这就使得等待线程一直处于等待状态，从而使其任务一直无法进展。

- **嵌套监视器锁死：**
  - 嵌套监视器锁死是由于嵌套锁导致等待线程永远无法被唤醒的一种故障。
  - 比如一个线程，只释放了内层锁Y.wait()，但是没有释放外层锁X; 但是通知线程必须先获得外层锁X，才可以通过 Y.notifyAll()来唤醒等待线程，这就导致出现了嵌套等待现象。

### 活锁：

活锁是一种特殊的线程活性故障。当一个线程一直处于运行状态，但是其所执行的任务却没有任何进展称为活锁。比如，一个线程一直在申请其所需要的资源，但是却无法申请成功。



### 线程饥饿：

线程饥饿是指线程一直无法获得其所需的资源导致任务一直无法运行的情况。线程调度模式有公平调度和非公平调度两种模式。**在线程的非公平调度模式下**，就可能出现线程饥饿的情况。



### 线程活性故障总结

- 线程饥饿发生时，如果线程处于可运行状态，也就是其一直在申请资源，那么就会转变为活锁
- 只要存在一个或多个线程因为获取不到其所需的资源而无法进展就是线程饥饿，所以线程死锁其实也算是线程饥饿



## 原子性，可见性与有序性

- 多线程环境下的线程安全主要体现在**原子性，可见性与有序性**方面。



### 原子性

- **定义：**对于涉及到共享变量访问的操作，若该操作从执行线程以外的任意线程来看是不可分割的，那么该操作就是原子操作，该操作具有原子性。即，其它线程不会“看到”该操作执行了部分的中间结果。

- **举例：**银行转账流程中，A账户减少了100元，那么B账户就会多100元，这两个动作是一个原子操作。我们不会看到A减少了100元，但是B余额保持不变的中间结果。

- **实现方式：**
  - 利用**锁的排他性**，保证同一时刻只有一个线程在操作一个共享变量
  - 利用**CAS（Compare And Swap）**保证
  - Java**语言规范中**，保证了除long和double型以外的任何变量的写操作都是原子操作
  - Java**语言规范**中又规定，volatile关键字修饰的变量可以保证其写操作的原子性

- **注意：**
  - 原子性针对的是多个线程的共享变量，所以对于局部变量来说不存在共享问题，也就无所谓是否是原子操作
  - 单线程环境下讨论是否是原子操作没有意义
  - volatile关键字仅仅能保证变量写操作的原子性，不保证复合操作，比如说读写操作的原子性



### 可见性

- **定义：**可见性是指一个线程对于共享变量的更新，对于后续访问该变量的线程是否可见的问题。

- **处理器缓存**
  - 现代处理器处理速度远大于主内存的处理速度，所以在主内存和处理器之间加入了寄存器，高速缓存，写缓冲器以及无效化队列等部件来加速内存的读写操作。也就是说，我们的处理器可以和这些部件进行读写操作的交互，这些部件可以称为处理器缓存。
  - 处理器对内存的读写操作，其实仅仅是与处理器缓存进行了交互。一个处理器的缓存上的内容无法被另外一个处理器读取，所以另外一个处理器必须通过缓存一致性协议来读取的其他处理器缓存中的数据，并且同步到自己的处理器缓存中，这样保证了其余处理器对该变量的更新对于另外处理器是可见的。

- **在单处理器中，为什么也会出现可见性的问题呢？**

  单处理器中，由于是多线程并发编程，所以会存在线程的上下文切换，线程会将对变量的更新当作上下文存储起来，导致其余线程无法看到该变量的更新。所以单处理器下的多线程并发编程也会出现可见性问题的。

- **可见性如何保证？**
  - 当前处理器需要**刷新处理器缓存**，使得其余处理器对变量所做的更新可以同步到当前的处理器缓存中
  - 当前处理器对共享变量更新之后，需要**冲刷处理器缓存**，使得该更新可以被写入处理器缓存中



### 有序性

- **定义：**有序性是指一个处理器上运行的线程所执行的内存访问操作在另外一个处理器上运行的线程来看是否有序的问题。

- **重排序：**
  - 为了提高程序执行的性能，Java编译器在其认为不影响程序正确性的前提下，可能会对源代码顺序进行一定的调整，导致程序运行顺序与源代码顺序不一致。
  - 重排序是对内存读写操作的一种优化，在单线程环境下不会导致程序的正确性问题，但是多线程环境下可能会影响程序的正确性。

- **重排序举例：**
  **Instance instance = new Instance()都发生了啥？**
  **具体步骤如下所示三步：**

  - 在堆内存上分配对象的内存空间
  - 在堆内存上初始化对象
  - 设置instance指向刚分配的内存地址

  第二步和第三步可能会发生重排序，导致引用型变量指向了一个不为null但是也不完整的对象。（**在多线程下的单例模式中，我们必须通过volatile来禁止指令重排序**）



### 总结

- **原子性**是一组操作要么完全发生，要么没有发生，其余线程不会看到中间过程的存在。注意，**原子操作+原子操作不一定还是原子操作。**
- **可见性**是指一个线程对共享变量的更新**对于另外一个线程是否可见**的问题。
- **有序性**是指一个线程对共享变量的更新在其余线程看起来是**按照什么顺序执行**的问题。
- 可以这么认为，**原子性 + 可见性 -> 有序性**



## **synchronized关键字**

**synchronized是Java中的一个关键字，是一个内部锁**。它可以使用在方法上和方法块上，表示同步方法和同步代码块。在多线程环境下，同步方法或者同步代码块在同一时刻只允许有一个线程在执行，其余线程都在等待获取锁，也就是实现了整体并发中的局部串行。



- **内部锁底层实现：**
  - 进入时，执行**monitorenter**，将计数器+1，释放锁**monitorexit**时，计数器-1
  - 当一个线程判断到计数器为0时，则当前锁空闲，可以占用；反之，当前线程进入等待状态

- **synchronized内部锁对原子性的保证：**

  锁通过互斥来保障原子性，互斥是指一个锁一次只能被一个线程所持有，所以，临界区代码只能被一个线程执行，即保障了原子性。

- **synchronized内部锁对可见性的保证：**

  synchronized内部锁通过写线程**冲刷处理器缓存**和读线程**刷新处理器缓存**保证可见性。

  - 获得锁之后，需要**刷新处理器缓存**，使得前面写线程所做的更新可以同步到本线程。
  - 释放锁需要**冲刷处理器缓存**，使得当前线程对共享数据的改变可以被推送到下一个线程处理器的高速缓冲中。

- **synchronized内部锁对有序性的保证：**

  由于原子性和可见性的保证，使得写线程**在临界区中**所执行的一系列操作在读线程所执行的临界区**看起来像是完全按照源代码顺序执行的**，即保证了有序性。



锁做为一种资源，**JVM对资源的调度分为公平调度和非公平调度方式**。

### 公平调度方式：

按照**申请的先后顺序**授予资源的独占权。

### 非公平调度方式：

- 在该策略中，资源的持有线程释放该资源的时候，等待队列中一个线程会被唤醒，而该线程从被唤醒到其继续执行可能需要一段时间。在该段时间内，**新来的线程（活跃线程）**可以先被授予该资源的独占权。

- 如果新来的线程占用该资源的时间不长，那么它完全有可能在被唤醒的线程继续执行前释放相应的资源，从而不影响该被唤醒的线程申请资源。

### 优缺点分析：

**非公平调度策略：**

- 优点：吞吐率较高，单位时间内可以为更多的申请者调配资源
- 缺点：资源申请者申请资源所需的时间偏差可能较大，并可能出现线程饥饿的现象

**公平调度策略：**

- 优点：线程申请资源所需的时间偏差较小；不会出现线程饥饿的现象；适合在资源的持有线程占用资源的时间相对长或者资源的平均申请时间间隔相对长的情况下，或者对资源申请所需的时间偏差有所要求的情况下使用；
- 缺点：吞吐率较小



### JVM对synchronized内部锁的调度

JVM对内部锁的调度是一种**非公平的调度方式**，JVM会给每个内部锁分配一个**入口集（Entry Set）**，用于记录等待获得相应内部锁的线程。当锁被持有的线程释放的时候，该锁的入口集中的任意一个线程将会被唤醒，从而得到再次申请锁的机会。被唤醒的线程等待占用处理器运行时可能还有其他新的活跃线程与该线程抢占这个被释放的锁.



## volatile关键字

volatile关键字是一个轻量级的锁，**可以保证可见性和有序性，但是不保证原子性**

- volatile 可以保证**主内存和工作内存直接产生交互**，进行读写操作，保证可见性
- volatile 仅能保证变量**写操作的原子性**，不能保证读写操作的原子性。
- volatile可以**禁止指令重排序**（通过插入内存屏障），典型案例是在单例模式中使用。

**volatile变量的开销：**

volatile不会导致线程上下文切换，但是其读取变量的成本较高，因为其每次都需要从高速缓存或者主内存中读取，无法直接从寄存器中读取变量。

**volatile在什么情况下可以替代锁？**

volatile是一个轻量级的锁，适合多个线程**共享一个状态变量**，锁适合多个线程**共享一组状态变量**。可以**将多个线程共享的一组状态变量合并成一个对象**，用一个volatile变量来引用该对象，从而替代锁。

## ReentrantLock和synchronized的区别

- ReentrantLock**是显示锁**，其提供了一些内部锁不具备的特性，但并不是内部锁的替代品。**显式锁支持公平和非公平的调度方式**，默认采用非公平调度。

- synchronized 内部锁简单，但是不灵活。显示锁支持在一个方法内申请锁，并且在另一个方法里释放锁。**显示锁定义了一个tryLock（）方法，尝试去获取锁**，成功返回true，失败并不会导致其执行的线程被暂停而是直接返回false，即可以**避免死锁**。





## 线程池

java.util.concurrent.ThreadPoolExecutor类就是一个线程池。客户端调ThreadPoolExecutor.submit(Runnable task)提交任务，线程池内部维护的工作者线程的数量就是该线程池的线程池大小，有3种形态：

- **当前线程池大小**：表示线程池中实际工作者线程的数量
- **最大线程池大小（maxinumPoolSize）**：表示线程池中允许存在的工作者线程的数量上限
- **核心线程大小（corePoolSize ）**：表示一个不大于最大线程池大小的工作者线程数量上限



**线程池的优势体现如下：**

- 线程池可以重复利用已创建的线程，一次创建可以执行多次任务，有效降低线程创建和销毁所造成的资源消耗；
- 线程池技术使得请求可以快速得到响应，节约了创建线程的时间；
- 线程的创建需要占用系统内存，消耗系统资源，使用线程池可以更好的管理线程，做到统一分配、调优和监控线程，提高系统的稳定性。

```java
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) 
```

JDK对各个字段的解释：

- **corePoolSize：核心线程数**
- **maximumPoolSize：最大线程数**
- **keepAliveTime ：线程空闲但是保持不被回收的时间**
- **unit：时间单位**
- **workQueue：存储线程的队列**
- **threadFactory：创建线程的工厂**
- **handler：拒绝策略**



**线程池的排队策略：**

当我们向线程池提交任务的时候，需要遵循一定的排队策略，具体策略如下：

- 如果运行的线程少于corePoolSize，则Executor始终首选添加新的线程，而不进行排队
- 如果运行的线程等于或者多于corePoolSize，则Executor始终首选将请求加入队列，而不是添加新线程
- 如果无法将请求加入队列，即队列已经满了，则创建新的线程，除非创建此线程超出maxinumPoolSize，在这种情况下，任务默认将被拒绝。



### 常见的线程池类型：

**newCachedThreadPool( )**

- 核心线程池大小为0，最大线程池大小不受限，来一个创建一个线程
- 适合用来执行大量耗时较短且提交频率较高的任务
- **内部队列使用了SynchronousQueue，所以不存在排队**



**newFixedThreadPool( )**

- 固定大小的线程池
- 当线程池大小达到核心线程池大小，就不会增加也不会减小工作者线程的固定大小的线程池



**newSingleThreadExecutor( )**

- 便于实现单（多）生产者-消费者模式



### 常见的阻塞队列：

前面我们介绍了线程池内部有一个排队策略，任务可能需要在队列中进行排队等候。常见的阻塞队列包括如下的三种，接下来我们一起来看看吧。

**ArrayBlockingQueue:**

- 内部使用一个**数组**作为其存储空间，数组的存储空间是**预先分配**的
- **优点是** put 和 take操作不会增加GC的负担（因为空间是预先分配的）
- **缺点是** put 和 take操作使用同一个锁，可能导致锁争用，导致较多的上下文切换。
- ArrayBlockingQueue适合在生产者线程和消费者线程之间的**并发程序较低**的情况下使用。



**LinkedBlockingQueue：**

- 是一个无界队列（其实队列长度是Integer.MAX_VALUE）
- 内部存储空间是一个**链表**，并且链表节点所需的**存储空间是动态分配**的
- **优点是** put 和 take 操作使用两个显式锁（putLock和takeLock）
- **缺点是**增加了GC的负担，因为空间是动态分配的。
- LinkedBlockingQueue适合在生产者线程和消费者线程之间的并发程序较高的情况下使用。



**SynchronousQueue：**
SynchronousQueue可以被看做一种特殊的有界队列。生产者线程生产一个产品之后，会等待消费者线程来取走这个产品，才会接着生产下一个产品，适合在生产者线程和消费者线程之间的处理能力相差不大的情况下使用。

### 注意事项

- 使用JDK提供的**快捷方式**创建线程池，比如说newCachedThreadPool会出现一些内存溢出的问题，因为**队列可以被塞入很多任务**。所以，大多数情况下，我们**都应该自定义线程池。**
- 线程池提供了一些**监控API**，可以很方便的监控当前以及塞进队列的任务数以及当前线程池已经完成的任务数等。

## ThreadLocal

使用ThreadLocal维护变量时，其为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立的改变自己的副本，而不会影响其他线程对应的副本。

**ThreadLocal内部实现机制：**

- 每个线程内部都会维护一个类似HashMap的对象，称为**ThreadLocalMap**，里边会包含若干了**Entry（K-V键值对）**，相应的线程被称为这些Entry的属主线程
- **Entry的Key是一个ThreadLocal实例，Value是一个线程特有对象**。Entry的作用是为其属主线程建立起一个ThreadLocal实例与一个线程特有对象之间的对应关系
- Entry对Key的引用是弱引用；Entry对Value的引用是强引用。

## Atmoic

i++操作并不是线程安全的，它是一个复合操作，包含三个步骤：

- **拷贝i的值到临时变量**
- **临时变量++操作**
- **拷贝回原始变量i**



这是一个**复合操作，不能保证原子性**，所以这不是线程安全的操作。

这里就用到了JDK在java.util.concurrent.atomic包下的AtomicInteger等原子类了。**AtomicInteger类提供了getAndIncrement和incrementAndGet等原子性的自增自减等操作**。**Atomic等原子类内部使用了CAS来保证原子性。**

```java
    
static int i = 0;
public void run() {
	for (int m = 0; m < 1000000; m++) {
		i++;
	}
}

static AtomicInteger i = new AtomicInteger(0);
    
public void run() {    
    for (int m = 0; m < 1000000; m++) { 
        i.getAndIncrement();
    }    
}
```





## CAS（Compare and Swap）

- synchronized 是一种悲观锁，始终假定会发生并发冲突，因此会屏蔽一切可能会违反数据一致性的操作
- 乐观锁假设不会发生并发冲突，因此，只在提交操作时检查是否违反数据完整性，如果失败，则会重试，最常见的乐观锁就是 CAS

- CAS 是一种高效实现线程安全性的方法

- 支持原子更新操作，适用于计数器，序列发生器等场景（给变量自增的工具）
- 属于乐观锁机制，号称 lock-free
- CAS 操作失败时由开发者决定是继续尝试，还是执行别的操作
- CAS 包含三个操作数 --- 内存位置 V（主内存）、预期原值 A 和 新值 B
  - 操作时，将内存位置的值与预期值比较，如果相匹配，处理器自动将新值B更新到内存位置，否则处理器不做任何操作
  - AtomicInteger 等原子类使用的就是 CAS
  - J.U.C的 atomic 包提供了常用的原子性数据类型以及引用、数组等相关原子类型和更新操作工具，是很多线程安全程序的首选

- Unsafe 类虽然提供 CAS 服务，但因能够操纵任意内存地址读写而有隐患

- JAVA 9 以后，可以用 Variable Handle API 来代替 Unsafe

  缺点：

  - 若循环时间长，则开销很大
  - 只能保证一个共享变量的原子操作
  - ABA问题，在操作期间，A->B->A，也会认为值没有改变过
    - 解决：AtomicStampedReference 带标记的原子引用类

## 锁的优化和注意事项

###  建议

####  减少锁持有时间

只在必要时进行同步，这样就能明显减少线程持有锁的时间，提高系统的吞吐量。

####  减小锁粒度

即减小锁定对象的范围，从而降低锁冲突的可能性，今儿提供系统的并发能力。对比ConcurrentHashMap、表锁-->行锁。

####  读写分离锁来替换独占锁

减小锁粒度是通过分割数据结构实现的，读写分离锁是通过对系统功能点的分割实现的。

####  锁粗化

虚拟机在遇到一连串连续地对同一个锁不断进行请求和释放的操作时，便会把所有的锁操作整合成对锁的一次请求，从而减少对锁的请求同步的次数。

```java
for(int i = 0 ; i < size; i++) {
  synchronized(lock) {
    ...
  }
}
/*意味着每次循环都要申请锁释放锁*/
synchronized(lock) {
  for(int i = 0; i < size; i++) {
    ...
  }
}
```

###  JVM中的锁优化

####  锁偏向

核心思想是如果一个线程获得了锁，那么锁就会进入偏向模式。当这个线程（只针对同一线程）再次请求锁时，无须再做任何同步操作。这样就节省了大量有关锁申请的操作，从而提高了程序性能。（在JVM参数中进行配置）

####  轻量级锁

如果偏向锁失败，那么虚拟机并不会立即挂起线程，将会使用一种称为轻量级锁的优化手段。简单的将对象头部作为指针指向持有锁的线程堆栈的内部，来判断一个线程是否持有对象锁。如果获得轻量级锁成功，则可以顺利进入临界区。如果轻量级锁加锁失败，那么就会膨胀为重量级锁。

####  自旋锁

当前线程暂时无法获得锁，而且什么时候可以获得锁是一个未知数，那么挂起一个线程将是得不偿失的操作，系统假设在不久的将来，线程可以得到这把锁。因此，虚拟机会让当前线程做几个空循环（自旋），在经过若干次循环后，如果可以得到锁，那么就顺利进入临界区，否则就会被挂起。

####  锁消除

是一种更彻底的锁优化，在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁。通过锁消除，可以节省毫无意义的请求锁时间。

```java
public String[] createStrings() {
  Vector<String> v= new Vector<String>();
}
```

可以看出，v是一个单纯的局部变量，而局部变量是在线程栈上分配的，属于私有数据，不可能被其它线程访问，在这种情况下，内部所有加锁同步都是没有必要的。如果虚拟机检测到这种情况，那么就会将无用的锁操作去除。这涉及到一种技术为逃逸分析，逃逸分析就是观察某一变量是否会逃出某一作用域。